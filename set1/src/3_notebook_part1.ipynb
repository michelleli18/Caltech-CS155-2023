{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuZm/uOLJaQWJUfaMle/3/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emiletimothy/Caltech-CS155-2023/blob/main/set1/src/3_notebook_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem 3, Parts D-F: Stochastic Gradient Descent Visualization**\n",
        "\n",
        "In this Jupyter notebook, we visualize how SGD works. This visualization corresponds to parts D-F of question 3 in set 1.\n",
        "\n",
        "Use this notebook to write your code for problem 3 parts D-F by filling in the sections marked # TODO and running all cells."
      ],
      "metadata": {
        "id": "8bPK9TklqPvd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBs3sSnDqKf6",
        "outputId": "2764c0f2-1557-462e-975f-aa77c353757b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [C\r                                                                               \rHit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connected to developer.\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rHit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "imagemagick is already the newest version (8:6.9.7.4+dfsg-16ubuntu6.14).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Install a package\n",
        "!apt-get update\n",
        "!apt install imagemagick"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, Image\n",
        "from matplotlib import animation, rc\n",
        "\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/set1/src/sgd_helper.py', 'sgd_helper.py')\n",
        "\n",
        "from sgd_helper import (\n",
        "    generate_dataset1,\n",
        "    generate_dataset2,\n",
        "    plot_dataset,\n",
        "    plot_loss_function,\n",
        "    animate_convergence,\n",
        "    animate_sgd_suite\n",
        ")"
      ],
      "metadata": {
        "id": "ylXsSW5wqWEW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3D: Implementation of SGD\n",
        "\n",
        "Fill in the loss, gradient, and SGD functions according to the guidelines given in the problem statement in order to perform SGD."
      ],
      "metadata": {
        "id": "U4iBQyJSqcLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(X, Y, w):\n",
        "    '''\n",
        "    Calculate the squared loss function.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing the data points.\n",
        "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
        "        w: A (D, ) shaped numpy array containing the weight vector.\n",
        "    \n",
        "    Outputs:\n",
        "        The loss evaluated with respect to X, Y, and w.\n",
        "    '''\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement the SGD loss function.\n",
        "    #==============================================\n",
        "    \n",
        "    pass\n",
        "\n",
        "def gradient(x, y, w):\n",
        "    '''\n",
        "    Calculate the gradient of the loss function with respect to the weight vector w,\n",
        "    evaluated at a single point (x, y) and weight vector w.\n",
        "    \n",
        "    Inputs:\n",
        "        x: A (D, ) shaped numpy array containing a single data point.\n",
        "        y: The float label for the data point.\n",
        "        w: A (D, ) shaped numpy array containing the weight vector.\n",
        "        \n",
        "    Output:\n",
        "        The gradient of the loss with respect to w. \n",
        "    '''\n",
        "\n",
        "    #==============================================\n",
        "    # TODO: Implement the gradient of the\n",
        "    # loss function.\n",
        "    #==============================================    \n",
        "    \n",
        "    pass\n",
        "\n",
        "def SGD(X, Y, w_start, eta, N_epochs):\n",
        "    '''\n",
        "    Perform SGD using dataset (X, Y), initial weight vector w_start,\n",
        "    learning rate eta, and N_epochs epochs.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing the data points.\n",
        "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
        "        w_start:  A (D, ) shaped numpy array containing the weight vector initialization.\n",
        "        eta: The step size.\n",
        "        N_epochs: The number of epochs (iterations) to run SGD.\n",
        "        \n",
        "    Outputs:\n",
        "        W: A (N_epochs, D) shaped array containing the weight vectors from all iterations.\n",
        "        losses: A (N_epochs, ) shaped array containing the losses from all iterations.\n",
        "    '''\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement the SGD algorithm.\n",
        "    #==============================================    \n",
        "    \n",
        "    pass"
      ],
      "metadata": {
        "id": "YANZUH73qYWd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3E: Visualization\n",
        "\n",
        "## Dataset\n",
        "\n",
        "We'll start off by generating two simple 2-dimensional datasets. For simplicity we do not consider separate training and test sets."
      ],
      "metadata": {
        "id": "cndQq5bkqj0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X1, Y1 = generate_dataset1()\n",
        "plot_dataset(X1, Y1)"
      ],
      "metadata": {
        "id": "pQHKc3VQqgWQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2, Y2 = generate_dataset2()\n",
        "plot_dataset(X2, Y2)"
      ],
      "metadata": {
        "id": "3TclZdfuqvBZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SGD from a single point\n",
        "First, let's visualize SGD from a single starting point:"
      ],
      "metadata": {
        "id": "OUl35d8lq9ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to feed the SGD.\n",
        "# <FR> changes the animation speed.\n",
        "params = ({'w_start': [0.01, 0.01], 'eta': 0.00001},)\n",
        "N_epochs = 1000\n",
        "FR = 20\n",
        "\n",
        "# Let's animate it!\n",
        "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR)\n",
        "anim.save('animation1.gif', fps=30, writer='imagemagick')\n",
        "Image(open('animation1.gif','rb').read())"
      ],
      "metadata": {
        "id": "oIZzdmNyqw42"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's view how the weights change as the algorithm converges:"
      ],
      "metadata": {
        "id": "cocPBSaIrCtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to feed the SGD.\n",
        "params = ({'w_start': [0.01, 0.01], 'eta': 0.00001},)\n",
        "N_epochs = 1000\n",
        "FR = 20\n",
        "\n",
        "# Let's do it!\n",
        "W, _ = SGD(X1, Y1, params[0]['w_start'], params[0]['eta'], N_epochs)\n",
        "anim = animate_convergence(X1, Y1, W, FR)\n",
        "anim.save('animation2.gif', fps=30, writer='imagemagick')\n",
        "Image(open('animation2.gif','rb').read())"
      ],
      "metadata": {
        "id": "xOGwkis7qyYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SGD from multiple points\n",
        "\n",
        "Now, let's visualize SGD from multiple arbitrary starting points:\n",
        "\n"
      ],
      "metadata": {
        "id": "NMklbCZTrLai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to feed the SGD.\n",
        "# Here, we specify each different set of initializations as a dictionary.\n",
        "params = (\n",
        "    {'w_start': [-0.8, -0.3], 'eta': 0.00001},\n",
        "    {'w_start': [-0.9, 0.4], 'eta': 0.00001},\n",
        "    {'w_start': [-0.4, 0.9], 'eta': 0.00001},\n",
        "    {'w_start': [0.8, 0.8], 'eta': 0.00001},\n",
        ")\n",
        "N_epochs = 1000\n",
        "FR = 20\n",
        "\n",
        "# Let's go!\n",
        "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR)\n",
        "anim.save('animation3.gif', fps=30, writer='imagemagick')\n",
        "Image(open('animation3.gif','rb').read())"
      ],
      "metadata": {
        "id": "f-gj_OWbrF64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do the same thing but with a different dataset:"
      ],
      "metadata": {
        "id": "IVXFYYIcrUfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to feed the SGD.\n",
        "params = (\n",
        "    {'w_start': [-0.8, -0.3], 'eta': 0.00001},\n",
        "    {'w_start': [-0.9, 0.4], 'eta': 0.00001},\n",
        "    {'w_start': [-0.4, 0.9], 'eta': 0.00001},\n",
        "    {'w_start': [0.8, 0.8], 'eta': 0.00001},\n",
        ")\n",
        "N_epochs = 1000\n",
        "FR = 20\n",
        "\n",
        "# Animate!\n",
        "anim = animate_sgd_suite(SGD, loss, X2, Y2, params, N_epochs, FR)\n",
        "anim.save('animation4.gif', fps=30, writer='imagemagick')\n",
        "Image(open('animation4.gif','rb').read())"
      ],
      "metadata": {
        "id": "nq9K8LEXrRzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3F: SGD with different step sizes\n",
        "\n",
        "Now, let's visualize SGD with different step sizes (eta):\n",
        "\n",
        "(For ease of visualization: the trajectories are ordered from left to right by decreasing eta value. Also, note that we use smaller values of N_epochs and FR here for easier visualization.)"
      ],
      "metadata": {
        "id": "VAuAhBSkrXJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to feed the SGD.\n",
        "params = (\n",
        "    {'w_start': [0.7, 0.8], 'eta': 0.00001},\n",
        "    { 'w_start': [0.2, 0.8], 'eta': 0.00005},\n",
        "    {'w_start': [-0.2, 0.7], 'eta': 0.0001},\n",
        "    {'w_start': [-0.6, 0.6], 'eta': 0.0002},\n",
        ")\n",
        "N_epochs = 100\n",
        "FR = 2\n",
        "\n",
        "# Go!\n",
        "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR, ms=2)\n",
        "anim.save('animation5.gif', fps=30, writer='imagemagick')\n",
        "Image(open('animation5.gif','rb').read())"
      ],
      "metadata": {
        "id": "SGZ2bj6Dra35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, a big step size results in fast convergence! Why don't we just set eta to a really big value, then? Say, eta=1?\n",
        "\n",
        "(Again, note that the FR is lower for this animation.)"
      ],
      "metadata": {
        "id": "ieap21znrhgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Plotting SGD convergence'''\n",
        "\n",
        "#==============================================\n",
        "# TODO: For the given learning rates, plot the \n",
        "# loss for each epoch.\n",
        "#==============================================\n",
        "\n",
        "eta_vals = [1e-6, 5e-6, 1e-5, 3e-5, 1e-4]\n",
        "w_start = [0.01, 0.01]\n",
        "N_epochs = 1000"
      ],
      "metadata": {
        "id": "5DMf8v1urfUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just for fun, let's try eta=10 as well. What happens? (Hint: look at W)"
      ],
      "metadata": {
        "id": "NvWrY_7erkfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to feed the SGD.\n",
        "w_start = [0.01, 0.01]\n",
        "eta = 10\n",
        "N_epochs = 100\n",
        "\n",
        "# Presto!\n",
        "W, losses = SGD(X1, Y1, w_start, eta, N_epochs)"
      ],
      "metadata": {
        "id": "LKiYabFzrrLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Visualization (not part of the homework problem)\n",
        "One final visualization! What happens if the loss function has multiple optima?"
      ],
      "metadata": {
        "id": "uxyg9GIvrt_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/set1/src/sgd_multiopt_helper.py', 'sgd_multiopt_helper.py')\n",
        "\n",
        "# Import different SGD & loss functions.\n",
        "# In particular, the loss function has multiple optima.\n",
        "from sgd_multiopt_helper import SGD, loss\n",
        "\n",
        "# Parameters to feed the SGD.\n",
        "params = (\n",
        "    {'w_start': [0.9, 0.9], 'eta': 0.01},\n",
        "    { 'w_start': [0.0, 0.0], 'eta': 0.01},\n",
        "    {'w_start': [-0.8, 0.6], 'eta': 0.01},\n",
        "    {'w_start': [-0.8, -0.6], 'eta': 0.01},\n",
        "    {'w_start': [-0.4, -0.3], 'eta': 0.01},\n",
        ")\n",
        "N_epochs = 100\n",
        "FR = 2\n",
        "\n",
        "# One more time!\n",
        "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR, ms=2)\n",
        "anim.save('animation7.gif', fps=30, writer='imagemagick')\n",
        "Image(open('animation7.gif','rb').read())"
      ],
      "metadata": {
        "id": "gWBS3lJarxai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}