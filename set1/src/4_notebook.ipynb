{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVLLgkshtNTR9lIfXPiPSX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emiletimothy/Caltech-CS155-2023/blob/main/set1/src/4_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem 4**\n",
        "\n",
        "Use this notebook to write your code for problem 4 by filling in the sections marked `# TODO` and running all cells."
      ],
      "metadata": {
        "id": "eBxKbwm_thzW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H0SHFUpMtHUs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/set1/src/perceptron_helper.py', 'perceptron_helper.py')\n",
        "\n",
        "\n",
        "from perceptron_helper import (\n",
        "    predict,\n",
        "    plot_data,\n",
        "    boundary,\n",
        "    plot_perceptron,\n",
        ")\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of Perceptron\n",
        "\n",
        "First, we will implement the perceptron algorithm. Fill in the `update_perceptron()` function so that it finds a single misclassified point and updates the weights and bias accordingly. If no point exists, the weights and bias should not change.\n",
        "\n",
        "Hint: You can use the `predict()` helper method, which labels a point 1 or -1 depending on the weights and bias."
      ],
      "metadata": {
        "id": "yI4orP6ctsV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_perceptron(X, Y, w, b):\n",
        "    \"\"\"\n",
        "    This method updates a perceptron model. Takes in the previous weights\n",
        "    and returns weights after an update, which could be nothing.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing a single point.\n",
        "        Y: A (N, ) shaped numpy array containing the labels for the points.\n",
        "        w: A (D, ) shaped numpy array containing the weight vector.\n",
        "        b: A float containing the bias term.\n",
        "    \n",
        "    Output:\n",
        "        next_w: A (D, ) shaped numpy array containing the next weight vector\n",
        "                after updating on a single misclassified point, if one exists.\n",
        "        next_b: The next float bias term after updating on a single\n",
        "                misclassified point, if one exists.\n",
        "        misclassified: The misclassified point used to update perceptron.\n",
        "    \"\"\"\n",
        "    next_w, next_b = np.copy(w), np.copy(b)\n",
        "    misclassified = None\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement update rule for perceptron.\n",
        "    #===============================================\n",
        "    \n",
        "    return next_w, next_b, misclassified"
      ],
      "metadata": {
        "id": "R2MJIMJBta0h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next you will fill in the `run_perceptron()` method. The method performs single updates on a misclassified point until convergence, or max_iter updates are made. The function will return the final weights and bias. You should use the `update_perceptron()` method you implemented above.\n",
        "\n"
      ],
      "metadata": {
        "id": "AJ8r3SG0tx_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_perceptron(X, Y, w, b, max_iter):\n",
        "    \"\"\"\n",
        "    This method runs the perceptron learning algorithm. Takes in initial weights\n",
        "    and runs max_iter update iterations. Returns final weights and bias.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing a single point.\n",
        "        Y: A (N, ) shaped numpy array containing the labels for the points.\n",
        "        w: A (D, ) shaped numpy array containing the initial weight vector.\n",
        "        b: A float containing the initial bias term.\n",
        "        max_iter: An int for the maximum number of updates evaluated.\n",
        "        \n",
        "    Output:\n",
        "        w: A (D, ) shaped numpy array containing the final weight vector.\n",
        "        b: The final float bias term.\n",
        "    \"\"\"\n",
        "    \n",
        "    #============================================\n",
        "    # TODO: Implement perceptron update loop.\n",
        "    #=============================================\n",
        "\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "ox15TFgttq4H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 4A\n",
        "\n",
        "## Visualizing a Toy Dataset\n",
        "\n",
        "We will begin by training our perceptron on a toy dataset of 3 points. The green points are labelled +1 and the red points are labelled -1. We use the helper function `plot_data()` to do so."
      ],
      "metadata": {
        "id": "ZGt-ryrYt2O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[ -3, -1], [0, 3], [1, -2]])\n",
        "Y = np.array([ -1, 1, 1])"
      ],
      "metadata": {
        "id": "RU6Po39Et0Ja"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(5,4))\n",
        "ax = fig.gca(); ax.set_xlim(-4.1, 3.1); ax.set_ylim(-3.1, 4.1)\n",
        "plot_data(X, Y, ax)"
      ],
      "metadata": {
        "id": "SsKog1e-t66Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the Perceptron\n",
        "\n",
        "Next, we will run the perceptron learning algorithm on this dataset. Update the code to show the weights and bias at each timestep and the misclassified point used in each update.\n",
        "\n",
        "Run the below code, and fill in the corresponding table in the set."
      ],
      "metadata": {
        "id": "wIok16dEt_46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and bias.\n",
        "weights = np.array([0.0, 1.0])\n",
        "bias = 0.0\n",
        "\n",
        "weights, bias = run_perceptron(X, Y, weights, bias, 16)\n",
        "\n",
        "print()\n",
        "print (\"final w = %s, final b = %.1f\" % (weights, bias))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0Y1upBot878",
        "outputId": "4559bc7f-768b-4865-b064-473d9591044b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "final w = [0. 1.], final b = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizating the Perceptron\n",
        "\n",
        "Getting all that information in table form isn't very informative. Let us visualize what the decision boundaries are at each timestep instead.\n",
        "\n",
        "The helper functions `boundary()` and `plot_perceptron()` plot a decision boundary given a perceptron weights and bias. Note that the equation for the decision boundary is given by:\n",
        "\n",
        "$$w_1 x_1 + w_2 x_2 + b = 0$$ \n",
        "\n",
        "Using some algebra, we can obtain $x_2$ from $x_1$ to plot the boundary as a line.\n",
        "\n",
        "$$ x_2 = \\frac{-w_1 x_1 - b}{w_2}$$\n",
        "\n",
        "Below is a redefinition of the `run_perceptron()` method to visualize the points and decision boundaries at each timestep instead of printing. Fill in the method using your previous `run_perceptron()` method, and the above helper methods.\n",
        "\n",
        "Hint: The axs element is a list of Axes, which are used as subplots for each timestep. You can do the following:\n",
        "\n",
        "\n",
        "```\n",
        "ax = axs[i]\n",
        "```\n",
        "\n",
        "to get the plot correponding to $t=i$. You can then use `ax.set_title()` to title each subplot. You will want to use the `plot_data()` and `plot_perceptron()` helper methods."
      ],
      "metadata": {
        "id": "KBwVts4QuJW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_perceptron(X, Y, w, b, axs, max_iter):\n",
        "    \"\"\"\n",
        "    This method runs the perceptron learning algorithm and plots data, weight, and bias at each timestep. \n",
        "    Takes in initial weights and runs max_iter update iterations. Returns final weights and bias.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing a single point.\n",
        "        Y: A (N, ) shaped numpy array containing the labels for the points.\n",
        "        w: A (D, ) shaped numpy array containing the initial weight vector.\n",
        "        b: A float containing the initial bias term.\n",
        "        axs: A list of Axes that contain suplots for each timestep. \n",
        "        max_iter: An int for the maximum number of updates evaluated.\n",
        "        \n",
        "    Output:\n",
        "        The final weight and bias vectors.\n",
        "    \"\"\"\n",
        "    \n",
        "    #============================================\n",
        "    # TODO: Implement perceptron update loop.\n",
        "    #=============================================\n",
        "\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "i8R_aAwNuD7g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below code to get a visualization of the perceptron algorithm. The red region are areas the perceptron thinks are negative examples.\n",
        "\n"
      ],
      "metadata": {
        "id": "djn9ofBYu9s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and bias.\n",
        "weights = np.array([0.0, 1.0])\n",
        "bias = 0.0\n",
        "\n",
        "f, ax_arr = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(9,8))\n",
        "axs = list(itertools.chain.from_iterable(ax_arr))\n",
        "for ax in axs:\n",
        "    ax.set_xlim(-4.1, 3.1); ax.set_ylim(-3.1, 4.1)\n",
        "\n",
        "run_perceptron(X, Y, weights, bias, axs, 4)\n",
        "\n",
        "f.tight_layout()"
      ],
      "metadata": {
        "id": "iJxu3fbAu7Ys"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 4C\n",
        "##Visualize a Non-linearly Separable Dataset.\n",
        "\n",
        "We will now work on a dataset that cannot be linearly separated, namely one that is generated by the XOR function."
      ],
      "metadata": {
        "id": "pkENeQwUvCuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
        "Y = np.array([1, 1, -1, -1])"
      ],
      "metadata": {
        "id": "VItmjuSBu_VV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(5,4))\n",
        "ax = fig.gca(); ax.set_xlim(-0.1, 1.1); ax.set_ylim(-0.1, 1.1)\n",
        "plot_data(X, Y, ax)"
      ],
      "metadata": {
        "id": "GPk8S51ovLp4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and bias.\n",
        "weights = np.array([0.0, 1.0])\n",
        "bias = 0.0\n",
        "\n",
        "f, ax_arr = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(9,8))\n",
        "axs = list(itertools.chain.from_iterable(ax_arr))\n",
        "for ax in axs:\n",
        "    ax.set_xlim(-0.1, 1.1); ax.set_ylim(-0.1, 1.1)\n",
        "    \n",
        "run_perceptron(X, Y, weights, bias, axs, 16)\n",
        "\n",
        "f.tight_layout()"
      ],
      "metadata": {
        "id": "jzRCzsayvM_s"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}