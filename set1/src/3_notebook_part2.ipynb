{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0h/mpWuSpkPkaE4HsFAOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emiletimothy/Caltech-CS155-2023/blob/main/set1/src/3_notebook_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem 3, Parts G-I: Stochastic Gradient Descent with a Larger Dataset**\n",
        "\n",
        "Use this notebook to write your code for problem 3 parts G-I by filling in the sections marked `# TODO` and running all cells.\n"
      ],
      "metadata": {
        "id": "UlFvO4gLocHN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fRpytxLvoImb"
      },
      "outputs": [],
      "source": [
        "# Setup.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3G: Perform SGD with the new dataset\n",
        "\n",
        "For the functions below, you may re-use your code from parts 3D-F. Note that you can now modify your SGD function to return the final weight vector instead of the weights after every epoch.\n",
        "\n"
      ],
      "metadata": {
        "id": "cWwb2t6Wo0iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(X, Y, w):\n",
        "    '''\n",
        "    Calculate the squared loss function.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing the data points.\n",
        "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
        "        w: A (D, ) shaped numpy array containing the weight vector.\n",
        "    \n",
        "    Outputs:\n",
        "        The loss evaluated with respect to X, Y, and w.\n",
        "    '''\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement the SGD loss function.\n",
        "    #==============================================\n",
        "    \n",
        "    pass\n",
        "\n",
        "def gradient(x, y, w):\n",
        "    '''\n",
        "    Calculate the gradient of the loss function with respect to\n",
        "    a single point (x, y), and using weight vector w.\n",
        "    \n",
        "    Inputs:\n",
        "        x: A (D, ) shaped numpy array containing a single data point.\n",
        "        y: The float label for the data point.\n",
        "        w: A (D, ) shaped numpy array containing the weight vector.\n",
        "        \n",
        "    Output:\n",
        "        The gradient of the loss with respect to x, y, and w. \n",
        "    '''\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement the gradient of the loss function.\n",
        "    #==============================================    \n",
        "    \n",
        "    pass\n",
        "\n",
        "def SGD(X, Y, w_start, eta, N_epochs):\n",
        "    '''\n",
        "    Perform SGD using dataset (X, Y), initial weight vector w_start,\n",
        "    learning rate eta, and N_epochs epochs.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing the data points.\n",
        "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
        "        w_start:  A (D, ) shaped numpy array containing the weight vector initialization.\n",
        "        eta: The step size.\n",
        "        N_epochs: The number of epochs (iterations) to run SGD.\n",
        "        \n",
        "    Outputs:\n",
        "        w: A (D, ) shaped array containing the final weight vector.\n",
        "        losses: A (N_epochs, ) shaped array containing the losses from all iterations.\n",
        "    '''\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement the SGD algorithm.\n",
        "    #==============================================    \n",
        "    \n",
        "    pass"
      ],
      "metadata": {
        "id": "xcpsinpnoxqT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to load the dataset. In doing so, the following function may be helpful:\n",
        "\n"
      ],
      "metadata": {
        "id": "P8K3Sj_JpC95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filename):\n",
        "    \"\"\"\n",
        "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
        "    \n",
        "    Inputs:\n",
        "        filename: GeneratorExitiven as a string.\n",
        "    \n",
        "    Outputs:\n",
        "        Data contained in the file, returned as a numpy ndarray\n",
        "    \"\"\"\n",
        "    return np.loadtxt(filename, skiprows=1, delimiter=',')"
      ],
      "metadata": {
        "id": "35vgOOKjo-fM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, load the dataset in ``sgd_data.csv`` and run SGD using the given parameters; print out the final weights."
      ],
      "metadata": {
        "id": "xsilTCfypJQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#==============================================\n",
        "# TODO:\n",
        "# (1) load the dataset\n",
        "# (2) run SGD using the given parameters\n",
        "# (3) print out the final weights.\n",
        "#==============================================\n",
        "\n",
        "# The following should help you get started:\n",
        "data = load_data('https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/set1/src/data/sgd_data.csv')"
      ],
      "metadata": {
        "id": "78YMbMqcpFjz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3H: Convergence of SGD\n",
        "\n",
        "This problem examines the convergence of SGD for different learning rates. Please implement your code in the cell below:"
      ],
      "metadata": {
        "id": "pLPqwWxYpQbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#==============================================\n",
        "# TODO: create a plot showing the convergence\n",
        "# of SGD for the different learning rates.\n",
        "#=============================================="
      ],
      "metadata": {
        "id": "C8RdVKO6pKHX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3I\n",
        "\n",
        "Provide your code for computing the least-squares analytical solution below.\n",
        "\n"
      ],
      "metadata": {
        "id": "n-Bti2CtpWX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#==============================================\n",
        "# TODO: implement the least-squares\n",
        "# analytical solution.\n",
        "#=============================================="
      ],
      "metadata": {
        "id": "gxeUrCN1pUgb"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}